name: YouTube Feed Scraper

on:
  schedule:
    # Daily at 6:00 UTC (7:00 CET / 8:00 CEST)
    - cron: '0 6 * * *'
  workflow_dispatch:
    inputs:
      max_videos:
        description: 'Max new videos to process'
        required: false
        default: '10'
      dry_run:
        description: 'Dry run (check only, no processing)'
        required: false
        type: boolean
        default: false

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install Python dependencies
        run: pip install youtube-transcript-api yt-dlp

      - name: Install npm dependencies
        run: npm ci

      - name: Run YouTube feed scraper
        run: |
          ARGS=""
          if [ "${{ github.event.inputs.max_videos }}" != "" ]; then
            ARGS="--max ${{ github.event.inputs.max_videos }}"
          else
            ARGS="--max 10"
          fi
          if [ "${{ github.event.inputs.dry_run }}" = "true" ]; then
            ARGS="$ARGS --dry-run"
          fi
          npx tsx scripts/blog-pipeline/youtube-feeds.ts $ARGS
        env:
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          XAI_API_KEY: ${{ secrets.XAI_API_KEY }}
